data:
  name: CIFAR100           # CIFAR100 or synthetic
  path: ./data
  batch_size: 256
  num_workers: 8
  pin_memory: true
  prefetch_factor: 4
  persistent_workers: true

model:
  name: resnet50           # torchvision model name
  num_classes: 100
  channels_last: true

training:
  epochs: 10
  precision: amp           # fp32 | amp | bf16
  optimizer: Adam          # Adam | SGD
  learning_rate: 0.001
  weight_decay: 0.0
  momentum: 0.9            # only if SGD
  grad_clip_norm: null     # or e.g. 1.0
  compile:
    enabled: true
    mode: default          # default | reduce-overhead | max-autotune
  seed: 1337
  cudnn_benchmark: true    # for throughput benchmarking

benchmark:
  enabled: true
  warmup_steps: 100
  measure_by: steps        # steps | time
  measure_steps: 2000
  measure_seconds: null
  log_step_times: true     # collect p50, p95
  sync_cuda: false         # set true for strict timing (slower)
  evaluate_after: false    # skip eval to isolate training throughput

distributed:
  backend: nccl
  gradient_accumulation_steps: 1
  world_size: null
  local_rank: null
  node_rank: null

run:
  experiment_name: resnet50_cifar100_scaling_test
  run_id: null             # auto timestamp/uuid if null
  save_dir: ./results
  capture_env: true        # GPU/driver/CUDA/PyTorch/NCCL vars
  commit_hash: auto        # read from git if available
  notes: "baseline run"
