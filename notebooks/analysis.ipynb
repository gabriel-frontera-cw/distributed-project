{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU Training Benchmark Suite â€” Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, os, glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "base = 'results'\n",
        "runs = []\n",
        "for summary_path in glob.glob(os.path.join(base, '*', '*', 'run_summary.json')):\n",
        "    with open(summary_path, 'r') as f:\n",
        "        d = json.load(f)\n",
        "    d['experiment'] = summary_path.split(os.sep)[1]\n",
        "    d['run'] = summary_path.split(os.sep)[2]\n",
        "    runs.append(d)\n",
        "\n",
        "df = pd.DataFrame(runs)\n",
        "print('Loaded runs:', len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Throughput vs GPU count (bar)\n",
        "if not df.empty:\n",
        "    sns.barplot(data=df, x='world_size', y='total_samples', estimator=sum)\n",
        "    plt.title('Total Samples by World Size')\n",
        "    plt.show()\n",
        "\n",
        "    # If per-epoch JSONL present, aggregate throughput per run\n",
        "    rows = []\n",
        "    for _, r in df.iterrows():\n",
        "        ep_path = os.path.join('results', r['experiment_name'], r['run_id'], 'metrics_epoch.jsonl')\n",
        "        if os.path.exists(ep_path):\n",
        "            with open(ep_path) as f:\n",
        "                for line in f:\n",
        "                    rows.append({**json.loads(line), 'run_id': r['run_id'], 'world_size': r['world_size']})\n",
        "    df_ep = pd.DataFrame(rows)\n",
        "    if not df_ep.empty:\n",
        "        plt.figure()\n",
        "        sns.barplot(data=df_ep, x='world_size', y='throughput_samples_per_s')\n",
        "        plt.title('Throughput (samples/s) by World Size')\n",
        "        plt.show()\n",
        "\n",
        "        # Scaling efficiency using median throughput across runs per world size\n",
        "        eff = (df_ep.groupby('world_size')['throughput_samples_per_s']\n",
        "                  .median()\n",
        "                  .rename('thr'))\n",
        "        if 1 in eff.index:\n",
        "            base = eff.loc[1]\n",
        "            eff_df = (eff / (eff.index * base)).reset_index()\n",
        "            eff_df.columns = ['world_size', 'scaling_efficiency']\n",
        "            plt.figure()\n",
        "            sns.lineplot(data=eff_df, x='world_size', y='scaling_efficiency', marker='o')\n",
        "            plt.ylim(0, 1.1)\n",
        "            plt.title('Scaling Efficiency')\n",
        "            plt.show()\n",
        "\n",
        "        # Step-time distributions (box)\n",
        "        plt.figure()\n",
        "        sns.boxplot(data=df_ep, x='world_size', y='p50_step_ms')\n",
        "        plt.title('Step-time p50 (ms) by World Size')\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure()\n",
        "        sns.boxplot(data=df_ep, x='world_size', y='p95_step_ms')\n",
        "        plt.title('Step-time p95 (ms) by World Size')\n",
        "        plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
